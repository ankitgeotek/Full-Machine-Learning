{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y=make_regression(n_samples=100, n_features=1, n_informative=1, n_targets=1,noise=20, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f3de39c350>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.82809103])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.29474455867698"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test, y_train, y_test= train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21.09901593,  18.03495551,  18.23747414,  -8.10292651,\n",
       "        15.72634513,  58.21059953, -15.03324179, -11.33105581,\n",
       "       -15.81005402,  -8.8082183 , -23.57512364,  14.78144416,\n",
       "        12.70150681, -23.8893975 , -22.30769518, -16.670531  ,\n",
       "        24.52827391, -16.98551717,  -3.88916883, -12.01966768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=lr.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345158782661012"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375011587464419"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(lr,x,y,scoring='r2',cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDRegressor:\n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.m=100\n",
    "        self.b=-120\n",
    "        self.lr=learning_rate\n",
    "        self.epochs=epochs\n",
    "\n",
    "    def fit(self,x,y):\n",
    "        #Calculating the b using Gradient descent\n",
    "        for i in range(self.epochs):\n",
    "            loss_slope_b= -2 * np.sum( y - self.m * x.ravel() - self.b)\n",
    "            loss_slope_m= -2 * np.sum( (y - self.m * x.ravel() - self.b)* x.ravel()) \n",
    "\n",
    "            self.b=self.b-(self.lr * loss_slope_b)\n",
    "            self.m=self.m-(self.lr * loss_slope_m)\n",
    "            \n",
    "            \n",
    "            print('epochs no=',i,'\\t\\t','Slope Loss of b is:',loss_slope_b, '\\tb b value is:',self.b,'\\n')\n",
    "            print('epochs no=',i,'\\t\\t','Slope Loss of m is:',loss_slope_m, '\\tb m value is:',self.m,'\\n')\n",
    "\n",
    "\n",
    "        print('\\n\\n the Value of b is:',self.b)\n",
    "        print('\\n\\n the Value of m is:',self.m)\n",
    "\n",
    "    def predict(self,x):\n",
    "        return self.m *x + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd=GDRegressor(learning_rate=0.001,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs no= 0 \t\t Slope Loss of b is: -22697.976504888527 \tb b value is: -97.30202349511147 \n",
      "\n",
      "epochs no= 0 \t\t Slope Loss of m is: 11209.822193922304 \tb m value is: 88.7901778060777 \n",
      "\n",
      "epochs no= 1 \t\t Slope Loss of b is: -18289.32849782429 \tb b value is: -79.01269499728718 \n",
      "\n",
      "epochs no= 1 \t\t Slope Loss of m is: 9520.283799304067 \tb m value is: 79.26989400677363 \n",
      "\n",
      "epochs no= 2 \t\t Slope Loss of b is: -14742.67378619848 \tb b value is: -64.2700212110887 \n",
      "\n",
      "epochs no= 2 \t\t Slope Loss of m is: 8073.854851267904 \tb m value is: 71.19603915550572 \n",
      "\n",
      "epochs no= 3 \t\t Slope Loss of b is: -11888.453588631008 \tb b value is: -52.381567622457695 \n",
      "\n",
      "epochs no= 3 \t\t Slope Loss of m is: 6838.213112591715 \tb m value is: 64.357826042914 \n",
      "\n",
      "epochs no= 4 \t\t Slope Loss of b is: -9590.643308507377 \tb b value is: -42.79092431395032 \n",
      "\n",
      "epochs no= 4 \t\t Slope Loss of m is: 5784.691756975142 \tb m value is: 58.573134285938856 \n",
      "\n",
      "epochs no= 5 \t\t Slope Loss of b is: -7740.088397628653 \tb b value is: -35.05083591632167 \n",
      "\n",
      "epochs no= 5 \t\t Slope Loss of m is: 4888.033694880779 \tb m value is: 53.685100591058074 \n",
      "\n",
      "epochs no= 6 \t\t Slope Loss of b is: -6249.170177294125 \tb b value is: -28.80166573902754 \n",
      "\n",
      "epochs no= 6 \t\t Slope Loss of m is: 4126.110891220014 \tb m value is: 49.55898969983806 \n",
      "\n",
      "epochs no= 7 \t\t Slope Loss of b is: -5047.535216383076 \tb b value is: -23.754130522644466 \n",
      "\n",
      "epochs no= 7 \t\t Slope Loss of m is: 3479.630315210599 \tb m value is: 46.07935938462746 \n",
      "\n",
      "epochs no= 8 \t\t Slope Loss of b is: -4078.675398879868 \tb b value is: -19.6754551237646 \n",
      "\n",
      "epochs no= 8 \t\t Slope Loss of m is: 2931.841277305026 \tb m value is: 43.14751810732243 \n",
      "\n",
      "epochs no= 9 \t\t Slope Loss of b is: -3297.1885591567166 \tb b value is: -16.378266564607884 \n",
      "\n",
      "epochs no= 9 \t\t Slope Loss of m is: 2468.2538486329686 \tb m value is: 40.679264258689464 \n",
      "\n",
      "epochs no= 10 \t\t Slope Loss of b is: -2666.583700922752 \tb b value is: -13.711682863685132 \n",
      "\n",
      "epochs no= 10 \t\t Slope Loss of m is: 2076.3743805099593 \tb m value is: 38.602889878179504 \n",
      "\n",
      "epochs no= 11 \t\t Slope Loss of b is: -2157.5220828601614 \tb b value is: -11.55416078082497 \n",
      "\n",
      "epochs no= 11 \t\t Slope Loss of m is: 1745.4615037738538 \tb m value is: 36.85742837440565 \n",
      "\n",
      "epochs no= 12 \t\t Slope Loss of b is: -1746.4072368446764 \tb b value is: -9.807753543980294 \n",
      "\n",
      "epochs no= 12 \t\t Slope Loss of m is: 1466.3041283982818 \tb m value is: 35.391124246007365 \n",
      "\n",
      "epochs no= 13 \t\t Slope Loss of b is: -1414.2543892292688 \tb b value is: -8.393499154751025 \n",
      "\n",
      "epochs no= 13 \t\t Slope Loss of m is: 1231.0216831889718 \tb m value is: 34.160102562818395 \n",
      "\n",
      "epochs no= 14 \t\t Slope Loss of b is: -1145.7836643754763 \tb b value is: -7.2477154903755485 \n",
      "\n",
      "epochs no= 14 \t\t Slope Loss of m is: 1032.8859813457066 \tb m value is: 33.12721658147269 \n",
      "\n",
      "epochs no= 15 \t\t Slope Loss of b is: -928.6925666048975 \tb b value is: -6.3190229237706514 \n",
      "\n",
      "epochs no= 15 \t\t Slope Loss of m is: 866.1635550418846 \tb m value is: 32.2610530264308 \n",
      "\n",
      "epochs no= 16 \t\t Slope Loss of b is: -753.0721239952185 \tb b value is: -5.5659507997754325 \n",
      "\n",
      "epochs no= 16 \t\t Slope Loss of m is: 725.9769840256439 \tb m value is: 31.53507604240516 \n",
      "\n",
      "epochs no= 17 \t\t Slope Loss of b is: -610.9381835300977 \tb b value is: -4.955012616245335 \n",
      "\n",
      "epochs no= 17 \t\t Slope Loss of m is: 608.183584390902 \tb m value is: 30.926892458014258 \n",
      "\n",
      "epochs no= 18 \t\t Slope Loss of b is: -495.8550301246038 \tb b value is: -4.459157586120731 \n",
      "\n",
      "epochs no= 18 \t\t Slope Loss of m is: 509.269775520752 \tb m value is: 30.417622682493505 \n",
      "\n",
      "epochs no= 19 \t\t Slope Loss of b is: -402.6330478953079 \tb b value is: -4.056524538225423 \n",
      "\n",
      "epochs no= 19 \t\t Slope Loss of m is: 426.2594698410292 \tb m value is: 29.991363212652477 \n",
      "\n",
      "epochs no= 20 \t\t Slope Loss of b is: -327.0857790332593 \tb b value is: -3.7294387591921634 \n",
      "\n",
      "epochs no= 20 \t\t Slope Loss of m is: 356.6349051149479 \tb m value is: 29.63472830753753 \n",
      "\n",
      "epochs no= 21 \t\t Slope Loss of b is: -265.8346461065429 \tb b value is: -3.4636041130856206 \n",
      "\n",
      "epochs no= 21 \t\t Slope Loss of m is: 298.2684434940768 \tb m value is: 29.33645986404345 \n",
      "\n",
      "epochs no= 22 \t\t Slope Loss of b is: -216.15193321442 \tb b value is: -3.2474521798712006 \n",
      "\n",
      "epochs no= 22 \t\t Slope Loss of m is: 249.3639818046488 \tb m value is: 29.087095882238803 \n",
      "\n",
      "epochs no= 23 \t\t Slope Loss of b is: -175.8344864961774 \tb b value is: -3.071617693375023 \n",
      "\n",
      "epochs no= 23 \t\t Slope Loss of m is: 208.40674405436295 \tb m value is: 28.87868913818444 \n",
      "\n",
      "epochs no= 24 \t\t Slope Loss of b is: -143.10208804046806 \tb b value is: -2.928515605334555 \n",
      "\n",
      "epochs no= 24 \t\t Slope Loss of m is: 174.12035337871126 \tb m value is: 28.70456878480573 \n",
      "\n",
      "epochs no= 25 \t\t Slope Loss of b is: -116.51565354965884 \tb b value is: -2.811999951784896 \n",
      "\n",
      "epochs no= 25 \t\t Slope Loss of m is: 145.4302023148169 \tb m value is: 28.559138582490913 \n",
      "\n",
      "epochs no= 26 \t\t Slope Loss of b is: -94.91136258196121 \tb b value is: -2.717088589202935 \n",
      "\n",
      "epochs no= 26 \t\t Slope Loss of m is: 121.43225471866793 \tb m value is: 28.437706327772243 \n",
      "\n",
      "epochs no= 27 \t\t Slope Loss of b is: -77.34759830540912 \tb b value is: -2.6397409908975256 \n",
      "\n",
      "epochs no= 27 \t\t Slope Loss of m is: 101.36651831275599 \tb m value is: 28.33633980945949 \n",
      "\n",
      "epochs no= 28 \t\t Slope Loss of b is: -63.06218942118538 \tb b value is: -2.57667880147634 \n",
      "\n",
      "epochs no= 28 \t\t Slope Loss of m is: 84.5945230688335 \tb m value is: 28.251745286390655 \n",
      "\n",
      "epochs no= 29 \t\t Slope Loss of b is: -51.437940616501294 \tb b value is: -2.525240860859839 \n",
      "\n",
      "epochs no= 29 \t\t Slope Loss of m is: 70.58022726300837 \tb m value is: 28.181165059127647 \n",
      "\n",
      "epochs no= 30 \t\t Slope Loss of b is: -41.97483388139826 \tb b value is: -2.483266026978441 \n",
      "\n",
      "epochs no= 30 \t\t Slope Loss of m is: 58.87385033379293 \tb m value is: 28.122291208793854 \n",
      "\n",
      "epochs no= 31 \t\t Slope Loss of b is: -34.2676007060724 \tb b value is: -2.4489984262723685 \n",
      "\n",
      "epochs no= 31 \t\t Slope Loss of m is: 49.0982001148093 \tb m value is: 28.073193008679045 \n",
      "\n",
      "epochs no= 32 \t\t Slope Loss of b is: -27.987620120600482 \tb b value is: -2.421010806151768 \n",
      "\n",
      "epochs no= 32 \t\t Slope Loss of m is: 40.93712223172547 \tb m value is: 28.03225588644732 \n",
      "\n",
      "epochs no= 33 \t\t Slope Loss of b is: -22.868302198603537 \tb b value is: -2.3981425039531645 \n",
      "\n",
      "epochs no= 33 \t\t Slope Loss of m is: 34.12575214864853 \tb m value is: 27.998130134298673 \n",
      "\n",
      "epochs no= 34 \t\t Slope Loss of b is: -18.693280989668345 \tb b value is: -2.3794492229634963 \n",
      "\n",
      "epochs no= 34 \t\t Slope Loss of m is: 28.442296246921625 \tb m value is: 27.96968783805175 \n",
      "\n",
      "epochs no= 35 \t\t Slope Loss of b is: -15.286872856136618 \tb b value is: -2.3641623501073594 \n",
      "\n",
      "epochs no= 35 \t\t Slope Loss of m is: 23.701108133454124 \tb m value is: 27.945986729918296 \n",
      "\n",
      "epochs no= 36 \t\t Slope Loss of b is: -12.506362263582332 \tb b value is: -2.351655987843777 \n",
      "\n",
      "epochs no= 36 \t\t Slope Loss of m is: 19.746860789498655 \tb m value is: 27.926239869128796 \n",
      "\n",
      "epochs no= 37 \t\t Slope Loss of b is: -10.235762335276853 \tb b value is: -2.3414202255085 \n",
      "\n",
      "epochs no= 37 \t\t Slope Loss of m is: 16.449644822828937 \tb m value is: 27.90979022430597 \n",
      "\n",
      "epochs no= 38 \t\t Slope Loss of b is: -8.380766036100233 \tb b value is: -2.3330394594724 \n",
      "\n",
      "epochs no= 38 \t\t Slope Loss of m is: 13.700848563817477 \tb m value is: 27.89608937574215 \n",
      "\n",
      "epochs no= 39 \t\t Slope Loss of b is: -6.864658993102346 \tb b value is: -2.3261748004792975 \n",
      "\n",
      "epochs no= 39 \t\t Slope Loss of m is: 11.409697581671537 \tb m value is: 27.884679678160477 \n",
      "\n",
      "epochs no= 40 \t\t Slope Loss of b is: -5.625009328385971 \tb b value is: -2.3205497911509116 \n",
      "\n",
      "epochs no= 40 \t\t Slope Loss of m is: 9.500349869456088 \tb m value is: 27.875179328291022 \n",
      "\n",
      "epochs no= 41 \t\t Slope Loss of b is: -4.610985592880226 \tb b value is: -2.3159388055580314 \n",
      "\n",
      "epochs no= 41 \t\t Slope Loss of m is: 7.909458881210124 \tb m value is: 27.86726986940981 \n",
      "\n",
      "epochs no= 42 \t\t Slope Loss of b is: -3.781182646031212 \tb b value is: -2.312157622912 \n",
      "\n",
      "epochs no= 42 \t\t Slope Loss of m is: 6.584130177789369 \tb m value is: 27.86068573923202 \n",
      "\n",
      "epochs no= 43 \t\t Slope Loss of b is: -3.1018584901562534 \tb b value is: -2.309055764421844 \n",
      "\n",
      "epochs no= 43 \t\t Slope Loss of m is: 5.480208980469634 \tb m value is: 27.855205530251553 \n",
      "\n",
      "epochs no= 44 \t\t Slope Loss of b is: -2.5455037340227165 \tb b value is: -2.3065102606878214 \n",
      "\n",
      "epochs no= 44 \t\t Slope Loss of m is: 4.560845731662315 \tb m value is: 27.85064468451989 \n",
      "\n",
      "epochs no= 45 \t\t Slope Loss of b is: -2.089680407340431 \tb b value is: -2.304420580280481 \n",
      "\n",
      "epochs no= 45 \t\t Slope Loss of m is: 3.7952950715653557 \tb m value is: 27.846849389448323 \n",
      "\n",
      "epochs no= 46 \t\t Slope Loss of b is: -1.7160789826247225 \tb b value is: -2.302704501297856 \n",
      "\n",
      "epochs no= 46 \t\t Slope Loss of m is: 3.1579106758496636 \tb m value is: 27.843691478772474 \n",
      "\n",
      "epochs no= 47 \t\t Slope Loss of b is: -1.409752250909989 \tb b value is: -2.301294749046946 \n",
      "\n",
      "epochs no= 47 \t\t Slope Loss of m is: 2.627304350596731 \tb m value is: 27.841064174421877 \n",
      "\n",
      "epochs no= 48 \t\t Slope Loss of b is: -1.1584925993012902 \tb b value is: -2.300136256447645 \n",
      "\n",
      "epochs no= 48 \t\t Slope Loss of m is: 2.185642808457743 \tb m value is: 27.83887853161342 \n",
      "\n",
      "epochs no= 49 \t\t Slope Loss of b is: -0.9523256183253039 \tb b value is: -2.2991839308293196 \n",
      "\n",
      "epochs no= 49 \t\t Slope Loss of m is: 1.818059793370221 \tb m value is: 27.837060471820052 \n",
      "\n",
      "\n",
      "\n",
      " the Value of b is: -2.2991839308293196\n",
      "\n",
      "\n",
      " the Value of m is: 27.837060471820052\n"
     ]
    }
   ],
   "source": [
    "gd.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-22.13004587],\n",
       "       [-14.46803398],\n",
       "       [-14.93031641],\n",
       "       [ 24.22481941],\n",
       "       [  4.3220791 ],\n",
       "       [ 21.67440917],\n",
       "       [ -9.07267152],\n",
       "       [  2.84916767],\n",
       "       [-22.36969544],\n",
       "       [-14.266255  ],\n",
       "       [ 53.79864004],\n",
       "       [  8.75884689],\n",
       "       [  3.48535872],\n",
       "       [ -8.76923699],\n",
       "       [-23.69550079],\n",
       "       [ 10.31541979],\n",
       "       [ 15.51330493],\n",
       "       [  7.70913832],\n",
       "       [-47.25904197],\n",
       "       [ 46.39456556],\n",
       "       [-24.26231913],\n",
       "       [-16.55078722],\n",
       "       [-28.14130775],\n",
       "       [ 57.56115677],\n",
       "       [ -8.07119002],\n",
       "       [-47.92672634],\n",
       "       [-11.72532075],\n",
       "       [-11.26615965],\n",
       "       [-15.69914914],\n",
       "       [-16.86253782],\n",
       "       [ 17.79820103],\n",
       "       [ 19.02152826],\n",
       "       [ 10.32439521],\n",
       "       [-37.41858492],\n",
       "       [-63.18204405],\n",
       "       [-35.29775901],\n",
       "       [  3.75403106],\n",
       "       [ 34.73292872],\n",
       "       [-32.56312362],\n",
       "       [ 13.35252918],\n",
       "       [-44.41234489],\n",
       "       [ -2.36568738],\n",
       "       [-10.04163129],\n",
       "       [ 10.27794346],\n",
       "       [ 30.84655074],\n",
       "       [ 23.3761659 ],\n",
       "       [ 20.3878935 ],\n",
       "       [-19.58543346],\n",
       "       [ 23.13667133],\n",
       "       [ 29.38866195],\n",
       "       [ 38.86308036],\n",
       "       [-20.42268251],\n",
       "       [-12.76369062],\n",
       "       [-23.86344212],\n",
       "       [ 11.65100525],\n",
       "       [ 35.28607828],\n",
       "       [ 17.99863937],\n",
       "       [ -4.57212324],\n",
       "       [-26.07601298],\n",
       "       [ 10.6633652 ],\n",
       "       [ -3.53801881],\n",
       "       [ -3.90071649],\n",
       "       [ 50.38919567],\n",
       "       [-31.39941033],\n",
       "       [ 13.41913163],\n",
       "       [-55.86212687],\n",
       "       [-23.56764375],\n",
       "       [  1.24456518],\n",
       "       [ -3.04442797],\n",
       "       [ -6.34144058],\n",
       "       [ 13.36881607],\n",
       "       [  6.5349329 ],\n",
       "       [ 17.49226443],\n",
       "       [ 18.68345633],\n",
       "       [-12.60212758],\n",
       "       [ 35.14449367],\n",
       "       [ 12.51953806],\n",
       "       [-29.69532713],\n",
       "       [ 35.28936573],\n",
       "       [-11.94769804],\n",
       "       [ 12.01821951],\n",
       "       [  0.51986922],\n",
       "       [-20.60253187],\n",
       "       [ 20.83078711],\n",
       "       [-11.13093595],\n",
       "       [-29.58713941],\n",
       "       [ 36.65150059],\n",
       "       [ 12.95325119],\n",
       "       [-17.06194005],\n",
       "       [ 11.36524495],\n",
       "       [  7.40900744],\n",
       "       [ 54.86959888],\n",
       "       [ 14.57811007],\n",
       "       [-13.00135576],\n",
       "       [-56.45314197],\n",
       "       [-11.06390724],\n",
       "       [ 49.18859292],\n",
       "       [-33.49080147],\n",
       "       [-11.5598996 ],\n",
       "       [-23.38445518]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs no= 0 \t\t Slope Loss of b is: -6.848320913489971 \tb b value is: -2.2923356099158294 \n",
      "\n",
      "epochs no= 0 \t\t Slope Loss of m is: -44.07414067726647 \tb m value is: 27.88113461249732 \n",
      "\n",
      "epochs no= 1 \t\t Slope Loss of b is: -5.39543553972608 \tb b value is: -2.2869401743761033 \n",
      "\n",
      "epochs no= 1 \t\t Slope Loss of m is: -37.32988420144089 \tb m value is: 27.91846449669876 \n",
      "\n",
      "epochs no= 2 \t\t Slope Loss of b is: -4.229663790080053 \tb b value is: -2.282710510586023 \n",
      "\n",
      "epochs no= 2 \t\t Slope Loss of m is: -31.62092017563819 \tb m value is: 27.950085416874398 \n",
      "\n",
      "epochs no= 3 \t\t Slope Loss of b is: -3.2966780104439266 \tb b value is: -2.279413832575579 \n",
      "\n",
      "epochs no= 3 \t\t Slope Loss of m is: -26.787804361633277 \tb m value is: 27.97687322123603 \n",
      "\n",
      "epochs no= 4 \t\t Slope Loss of b is: -2.5521350249607337 \tb b value is: -2.2768616975506184 \n",
      "\n",
      "epochs no= 4 \t\t Slope Loss of m is: -22.695730273912872 \tb m value is: 27.999568951509943 \n",
      "\n",
      "epochs no= 5 \t\t Slope Loss of b is: -1.9598789679064907 \tb b value is: -2.274901818582712 \n",
      "\n",
      "epochs no= 5 \t\t Slope Loss of m is: -19.230709206351477 \tb m value is: 28.018799660716294 \n",
      "\n",
      "epochs no= 6 \t\t Slope Loss of b is: -1.4904626175580233 \tb b value is: -2.273411355965154 \n",
      "\n",
      "epochs no= 6 \t\t Slope Loss of m is: -16.296344547395165 \tb m value is: 28.03509600526369 \n",
      "\n",
      "epochs no= 7 \t\t Slope Loss of b is: -1.1199314559228242 \tb b value is: -2.2722914245092314 \n",
      "\n",
      "epochs no= 7 \t\t Slope Loss of m is: -13.81110761261317 \tb m value is: 28.048907112876304 \n",
      "\n",
      "epochs no= 8 \t\t Slope Loss of b is: -0.8288243541541789 \tb b value is: -2.2714626001550773 \n",
      "\n",
      "epochs no= 8 \t\t Slope Loss of m is: -11.706036754558497 \tb m value is: 28.06061314963086 \n",
      "\n",
      "epochs no= 9 \t\t Slope Loss of b is: -0.6013527935245548 \tb b value is: -2.2708612473615526 \n",
      "\n",
      "epochs no= 9 \t\t Slope Loss of m is: -9.922793757278683 \tb m value is: 28.07053594338814 \n",
      "\n",
      "epochs no= 10 \t\t Slope Loss of b is: -0.4247271610143173 \tb b value is: -2.2704365202005383 \n",
      "\n",
      "epochs no= 10 \t\t Slope Loss of m is: -8.41202184663382 \tb m value is: 28.078947965234775 \n",
      "\n",
      "epochs no= 11 \t\t Slope Loss of b is: -0.2886041434426687 \tb b value is: -2.2701479160570956 \n",
      "\n",
      "epochs no= 11 \t\t Slope Loss of m is: -7.131958350918737 \tb m value is: 28.086079923585693 \n",
      "\n",
      "epochs no= 12 \t\t Slope Loss of b is: -0.18463378081655435 \tb b value is: -2.269963282276279 \n",
      "\n",
      "epochs no= 12 \t\t Slope Loss of m is: -6.047262384328704 \tb m value is: 28.09212718597002 \n",
      "\n",
      "epochs no= 13 \t\t Slope Loss of b is: -0.1060884909919082 \tb b value is: -2.269857193785287 \n",
      "\n",
      "epochs no= 13 \t\t Slope Loss of m is: -5.1280241134823115 \tb m value is: 28.097255210083503 \n",
      "\n",
      "epochs no= 14 \t\t Slope Loss of b is: -0.04755947877879407 \tb b value is: -2.269809634306508 \n",
      "\n",
      "epochs no= 14 \t\t Slope Loss of m is: -4.348927385414896 \tb m value is: 28.101604137468918 \n",
      "\n",
      "epochs no= 15 \t\t Slope Loss of b is: -0.004708505220094139 \tb b value is: -2.2698049258012882 \n",
      "\n",
      "epochs no= 15 \t\t Slope Loss of m is: -3.6885418966126053 \tb m value is: 28.10529267936553 \n",
      "\n",
      "epochs no= 16 \t\t Slope Loss of b is: 0.025934890318438875 \tb b value is: -2.2698308606916067 \n",
      "\n",
      "epochs no= 16 \t\t Slope Loss of m is: -3.1287247951270274 \tb m value is: 28.108421404160655 \n",
      "\n",
      "epochs no= 17 \t\t Slope Loss of b is: 0.04713887448689036 \tb b value is: -2.2698779995660936 \n",
      "\n",
      "epochs no= 17 \t\t Slope Loss of m is: -2.65411473970417 \tb m value is: 28.11107551890036 \n",
      "\n",
      "epochs no= 18 \t\t Slope Loss of b is: 0.0611042269106008 \tb b value is: -2.2699391037930043 \n",
      "\n",
      "epochs no= 18 \t\t Slope Loss of m is: -2.2517040822990424 \tb m value is: 28.113327222982658 \n",
      "\n",
      "epochs no= 19 \t\t Slope Loss of b is: 0.06957419522714758 \tb b value is: -2.2700086779882316 \n",
      "\n",
      "epochs no= 19 \t\t Slope Loss of m is: -1.910477070067941 \tb m value is: 28.115237700052727 \n",
      "\n",
      "epochs no= 20 \t\t Slope Loss of b is: 0.07392384149152065 \tb b value is: -2.2700826018297233 \n",
      "\n",
      "epochs no= 20 \t\t Slope Loss of m is: -1.6211038445974708 \tb m value is: 28.116858803897326 \n",
      "\n",
      "epochs no= 21 \t\t Slope Loss of b is: 0.07523261348538313 \tb b value is: -2.2701578344432085 \n",
      "\n",
      "epochs no= 21 \t\t Slope Loss of m is: -1.3756816043221676 \tb m value is: 28.11823448550165 \n",
      "\n",
      "epochs no= 22 \t\t Slope Loss of b is: 0.07434320713167608 \tb b value is: -2.2702321776503402 \n",
      "\n",
      "epochs no= 22 \t\t Slope Loss of m is: -1.1675156366137145 \tb m value is: 28.119402001138262 \n",
      "\n",
      "epochs no= 23 \t\t Slope Loss of b is: 0.07190923651840819 \tb b value is: -2.2703040868868585 \n",
      "\n",
      "epochs no= 23 \t\t Slope Loss of m is: -0.9909340577823542 \tb m value is: 28.120392935196044 \n",
      "\n",
      "epochs no= 24 \t\t Slope Loss of b is: 0.06843377546947238 \tb b value is: -2.270372520662328 \n",
      "\n",
      "epochs no= 24 \t\t Slope Loss of m is: -0.8411310547183319 \tb m value is: 28.12123406625076 \n",
      "\n",
      "epochs no= 25 \t\t Slope Loss of b is: 0.06430046217514018 \tb b value is: -2.270436821124503 \n",
      "\n",
      "epochs no= 25 \t\t Slope Loss of m is: -0.7140342287533059 \tb m value is: 28.121948100479514 \n",
      "\n",
      "epochs no= 26 \t\t Slope Loss of b is: 0.05979855210303242 \tb b value is: -2.270496619676606 \n",
      "\n",
      "epochs no= 26 \t\t Slope Loss of m is: -0.6061923236797924 \tb m value is: 28.122554292803194 \n",
      "\n",
      "epochs no= 27 \t\t Slope Loss of b is: 0.05514305265198516 \tb b value is: -2.270551762729258 \n",
      "\n",
      "epochs no= 27 \t\t Slope Loss of m is: -0.5146801953632689 \tb m value is: 28.123068972998556 \n",
      "\n",
      "epochs no= 28 \t\t Slope Loss of b is: 0.050490866183068306 \tb b value is: -2.2706022535954413 \n",
      "\n",
      "epochs no= 28 \t\t Slope Loss of m is: -0.4370183664726994 \tb m value is: 28.12350599136503 \n",
      "\n",
      "epochs no= 29 \t\t Slope Loss of b is: 0.04595369827781326 \tb b value is: -2.270648207293719 \n",
      "\n",
      "epochs no= 29 \t\t Slope Loss of m is: -0.37110492053000144 \tb m value is: 28.123877096285558 \n",
      "\n",
      "epochs no= 30 \t\t Slope Loss of b is: 0.04160834878210551 \tb b value is: -2.270689815642501 \n",
      "\n",
      "epochs no= 30 \t\t Slope Loss of m is: -0.3151578364275025 \tb m value is: 28.124192254121986 \n",
      "\n",
      "epochs no= 31 \t\t Slope Loss of b is: 0.0375048889885079 \tb b value is: -2.2707273205314897 \n",
      "\n",
      "epochs no= 31 \t\t Slope Loss of m is: -0.2676661577417718 \tb m value is: 28.12445992027973 \n",
      "\n",
      "epochs no= 32 \t\t Slope Loss of b is: 0.03367313477507139 \tb b value is: -2.270760993666265 \n",
      "\n",
      "epochs no= 32 \t\t Slope Loss of m is: -0.22734863893656154 \tb m value is: 28.124687268918667 \n",
      "\n",
      "epochs no= 33 \t\t Slope Loss of b is: 0.030127748927711195 \tb b value is: -2.2707911214151926 \n",
      "\n",
      "epochs no= 33 \t\t Slope Loss of m is: -0.19311871993461693 \tb m value is: 28.1248803876386 \n",
      "\n",
      "epochs no= 34 \t\t Slope Loss of b is: 0.02687224326628268 \tb b value is: -2.2708179936584587 \n",
      "\n",
      "epochs no= 34 \t\t Slope Loss of m is: -0.16405485755221605 \tb m value is: 28.125044442496154 \n",
      "\n",
      "epochs no= 35 \t\t Slope Loss of b is: 0.023902100010644745 \tb b value is: -2.2708418957584695 \n",
      "\n",
      "epochs no= 35 \t\t Slope Loss of m is: -0.13937539191323367 \tb m value is: 28.125183817888068 \n",
      "\n",
      "epochs no= 36 \t\t Slope Loss of b is: 0.021207190058035508 \tb b value is: -2.2708631029485273 \n",
      "\n",
      "epochs no= 36 \t\t Slope Loss of m is: -0.11841725246982548 \tb m value is: 28.125302235140538 \n",
      "\n",
      "epochs no= 37 \t\t Slope Loss of b is: 0.018773631781641598 \tb b value is: -2.270881876580309 \n",
      "\n",
      "epochs no= 37 \t\t Slope Loss of m is: -0.1006179152269624 \tb m value is: 28.125402853055764 \n",
      "\n",
      "epochs no= 38 \t\t Slope Loss of b is: 0.01658520621170112 \tb b value is: -2.2708984617865204 \n",
      "\n",
      "epochs no= 38 \t\t Slope Loss of m is: -0.08550011323058015 \tb m value is: 28.125488353168993 \n",
      "\n",
      "epochs no= 39 \t\t Slope Loss of b is: 0.014624421889010364 \tb b value is: -2.2709130862084095 \n",
      "\n",
      "epochs no= 39 \t\t Slope Loss of m is: -0.07265887888327427 \tb m value is: 28.125561012047875 \n",
      "\n",
      "epochs no= 40 \t\t Slope Loss of b is: 0.012873304340033087 \tb b value is: -2.2709259595127493 \n",
      "\n",
      "epochs no= 40 \t\t Slope Loss of m is: -0.06175056136873991 \tb m value is: 28.125622762609243 \n",
      "\n",
      "epochs no= 41 \t\t Slope Loss of b is: 0.011313970239029914 \tb b value is: -2.2709372734829882 \n",
      "\n",
      "epochs no= 41 \t\t Slope Loss of m is: -0.052483517204777286 \tb m value is: 28.12567524612645 \n",
      "\n",
      "epochs no= 42 \t\t Slope Loss of b is: 0.009929034263890912 \tb b value is: -2.2709472025172524 \n",
      "\n",
      "epochs no= 42 \t\t Slope Loss of m is: -0.04461021826861611 \tb m value is: 28.125719856344716 \n",
      "\n",
      "epochs no= 43 \t\t Slope Loss of b is: 0.008701886904646017 \tb b value is: -2.270955904404157 \n",
      "\n",
      "epochs no= 43 \t\t Slope Loss of m is: -0.03792056081464068 \tb m value is: 28.12575777690553 \n",
      "\n",
      "epochs no= 44 \t\t Slope Loss of b is: 0.007616873600753138 \tb b value is: -2.270963521277758 \n",
      "\n",
      "epochs no= 44 \t\t Slope Loss of m is: -0.032236192178558554 \tb m value is: 28.12579001309771 \n",
      "\n",
      "epochs no= 45 \t\t Slope Loss of b is: 0.006659399243801545 \tb b value is: -2.2709701806770015 \n",
      "\n",
      "epochs no= 45 \t\t Slope Loss of m is: -0.027405699921430937 \tb m value is: 28.12581741879763 \n",
      "\n",
      "epochs no= 46 \t\t Slope Loss of b is: 0.005815976974417936 \tb b value is: -2.2709759966539758 \n",
      "\n",
      "epochs no= 46 \t\t Slope Loss of m is: -0.023300531925102064 \tb m value is: 28.125840719329556 \n",
      "\n",
      "epochs no= 47 \t\t Slope Loss of b is: 0.005074236111227037 \tb b value is: -2.270981070890087 \n",
      "\n",
      "epochs no= 47 \t\t Slope Loss of m is: -0.019811536052500855 \tb m value is: 28.12586053086561 \n",
      "\n",
      "epochs no= 48 \t\t Slope Loss of b is: 0.004422900769057492 \tb b value is: -2.2709854937908562 \n",
      "\n",
      "epochs no= 48 \t\t Slope Loss of m is: -0.016846025022047684 \tb m value is: 28.12587737689063 \n",
      "\n",
      "epochs no= 49 \t\t Slope Loss of b is: 0.0038517481149256128 \tb b value is: -2.2709893455389714 \n",
      "\n",
      "epochs no= 49 \t\t Slope Loss of m is: -0.01432528654659393 \tb m value is: 28.125891702177178 \n",
      "\n",
      "\n",
      "\n",
      " the Value of b is: -2.2709893455389714\n",
      "\n",
      "\n",
      " the Value of m is: 28.125891702177178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test, y_train, y_test= train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "\n",
    "gd.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.0989732 ],\n",
       "       [ 18.03492167],\n",
       "       [ 18.23743972],\n",
       "       [ -8.1028845 ],\n",
       "       [ 15.72631799],\n",
       "       [ 58.21044911],\n",
       "       [-15.03317968],\n",
       "       [-11.33100444],\n",
       "       [-15.80998965],\n",
       "       [ -8.80817425],\n",
       "       [-23.57503674],\n",
       "       [ 14.78141976],\n",
       "       [ 12.70148845],\n",
       "       [-23.88930969],\n",
       "       [-22.30761196],\n",
       "       [-16.67046414],\n",
       "       [ 24.52822123],\n",
       "       [-16.9854494 ],\n",
       "       [ -3.88913906],\n",
       "       [-12.01961432]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=gd.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345162275128353"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
